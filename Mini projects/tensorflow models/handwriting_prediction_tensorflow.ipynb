{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MdGdRQP_1v1Y"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=np.load('/content/drive/MyDrive/model/data/processed/x.npy')"
      ],
      "metadata": {
        "id": "sk1yNN1f2EoP"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = np.roll(x, shift=-1, axis=1)\n",
        "y[:, -1, :] = 0\n",
        "print(x.shape)\n",
        "print(y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YkppSAZ99cwV",
        "outputId": "06b8cabd-73b7-412f-8c61-75d31bc80d87"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(11911, 1200, 3)\n",
            "(11911, 1200, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x[0][1])\n",
        "print(y[0][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k32WT50z-DBX",
        "outputId": "c9fd591d-aebb-4c29-a662-106959b49d44"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0.0217352 -0.3341787  0.       ]\n",
            "[ 0.0217352 -0.3341787  0.       ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def mixtureDensityParams(Z):\n",
        "    mdn_params = Z[:, :, 1:]\n",
        "\n",
        "    pi_hat, mu1_hat, mu2_hat, sigma1_hat, sigma2_hat, rho_hat = tf.split(mdn_params, 6, axis=-1)\n",
        "\n",
        "    eos_hat = Z[:, :, 0]\n",
        "    eos = tf.sigmoid(eos_hat)\n",
        "    rho = tf.tanh(rho_hat)\n",
        "    pi = tf.sigmoid(pi_hat)\n",
        "\n",
        "    sigma1 = tf.exp(sigma1_hat)\n",
        "    sigma2 = tf.exp(sigma2_hat)\n",
        "\n",
        "    mu1 = mu1_hat\n",
        "    mu2 = mu2_hat\n",
        "\n",
        "    return mu1, mu2, sigma1, sigma2, pi, eos, rho\n",
        "\n",
        "# Define the mixture density function\n",
        "def mixtureDensity(mu1, mu2, sigma1, sigma2, pi, eos, rho, x1, x2):\n",
        "    x_mu1 = x1 - mu1\n",
        "    x_mu2 = x2 - mu2\n",
        "    Z_out = tf.square(tf.divide(x_mu1, sigma1)) + tf.square(tf.divide(x_mu2, sigma2)) - 2 * tf.divide(rho * x_mu1 * x_mu2, sigma1 * sigma2)\n",
        "    rho_square_term = 1 - tf.square(rho)\n",
        "    power_e = tf.exp(tf.divide(-Z_out, 2 * rho_square_term))\n",
        "    regularize_term = 2 * tf.constant(np.pi, dtype=tf.float32) * sigma1 * sigma2 * tf.sqrt(rho_square_term)\n",
        "    gaussian = tf.divide(power_e, regularize_term)\n",
        "    return tf.reduce_sum(gaussian * pi)\n",
        "\n",
        "# Define the probability function\n",
        "def get_prob(x1, x2, eos_true, Z):\n",
        "    mu1, mu2, sigma1, sigma2, pi, eos, rho = mixtureDensityParams(Z)\n",
        "    eps = tf.constant(np.finfo(float).eps, dtype=tf.float32)\n",
        "    prob = 0.0\n",
        "    for i in range(20):\n",
        "        prob += mixtureDensity(mu1[:,:,i], mu2[:,:,i], sigma1[:,:,i], sigma2[:,:,i], pi[:,:,i], eos, rho[:,:,i], x1, x2)\n",
        "    return prob, tf.reduce_sum(tf.math.log(tf.squeeze((eos * (eos_true + eps) + (1 - eos) * (1 - eos_true + eps)))))\n",
        "\n",
        "def custom_loss(y_true, y_pred):\n",
        "    x1 = y_true[:, :, 0]\n",
        "    x2 = y_true[:, :, 1]\n",
        "    eos_true = y_true[:, :, 2]\n",
        "\n",
        "    prob, stroke_prob = get_prob(x1, x2, eos_true, y_pred)\n",
        "    loss=(-1)*(prob+stroke_prob)\n",
        "\n",
        "    return loss"
      ],
      "metadata": {
        "id": "FAvwlB2IldWk"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "class MyModel(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(MyModel, self).__init__()\n",
        "\n",
        "        self.lstm1 = tf.keras.layers.LSTM(400, return_sequences=True)\n",
        "        self.batch_norm1 = tf.keras.layers.BatchNormalization()\n",
        "\n",
        "        self.lstm2 = tf.keras.layers.LSTM(400, return_sequences=True)\n",
        "        self.batch_norm2 = tf.keras.layers.BatchNormalization()\n",
        "\n",
        "        self.lstm3 = tf.keras.layers.LSTM(400, return_sequences=True)\n",
        "        self.batch_norm3 = tf.keras.layers.BatchNormalization()\n",
        "\n",
        "        self.concatenate = tf.keras.layers.Concatenate(axis=-1)\n",
        "        self.dense1 = tf.keras.layers.Dense(600, activation='relu')\n",
        "        self.batch_norm4 = tf.keras.layers.BatchNormalization()\n",
        "\n",
        "        self.dense2 = tf.keras.layers.Dense(121, activation='relu')\n",
        "        self.batch_norm5 = tf.keras.layers.BatchNormalization()\n",
        "\n",
        "    def call(self, inputs, training=True):\n",
        "        x1 = self.lstm1(inputs)\n",
        "        x1 = self.batch_norm1(x1, training=training)\n",
        "\n",
        "        x2 = self.lstm2(x1)\n",
        "        x2 = self.batch_norm2(x2, training=training)\n",
        "\n",
        "        x3 = self.lstm3(x2)\n",
        "        x3 = self.batch_norm3(x3, training=training)\n",
        "\n",
        "        concatenated_output = self.concatenate([x1, x2, x3])\n",
        "\n",
        "        x = self.dense1(concatenated_output)\n",
        "        x = self.batch_norm4(x, training=training)\n",
        "\n",
        "        mdn_params = self.dense2(x)\n",
        "        mdn_params = self.batch_norm5(mdn_params, training=training)\n",
        "\n",
        "        return mdn_params\n",
        "\n",
        "model = MyModel()"
      ],
      "metadata": {
        "id": "CEdmIAhT2tiA"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.00001, clipvalue=10.0), loss=custom_loss)"
      ],
      "metadata": {
        "id": "fLoDqz1h8IuY"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.build((None,1200,3))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oON-OtyHi87J",
        "outputId": "adf2ab2b-46f2-4df0-c72c-ed67640d7a98"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"my_model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_6 (LSTM)               multiple                  646400    \n",
            "                                                                 \n",
            " batch_normalization (Batch  multiple                  1600      \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " lstm_7 (LSTM)               multiple                  1281600   \n",
            "                                                                 \n",
            " batch_normalization_1 (Bat  multiple                  1600      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " lstm_8 (LSTM)               multiple                  1281600   \n",
            "                                                                 \n",
            " batch_normalization_2 (Bat  multiple                  1600      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " concatenate_2 (Concatenate  multiple                  0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dense_4 (Dense)             multiple                  720600    \n",
            "                                                                 \n",
            " batch_normalization_3 (Bat  multiple                  2400      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense_5 (Dense)             multiple                  72721     \n",
            "                                                                 \n",
            " batch_normalization_4 (Bat  multiple                  484       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4010605 (15.30 MB)\n",
            "Trainable params: 4006763 (15.28 MB)\n",
            "Non-trainable params: 3842 (15.01 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x,y, batch_size=32, epochs=10)"
      ],
      "metadata": {
        "id": "ccC0Nf3-_oNa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/MyDrive/model/handwriting-prediction')"
      ],
      "metadata": {
        "id": "1Fp1jeBRE9H2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load('/content/drive/MyDrive/model/handwriting-prediction')\n",
        "example_index = 7\n",
        "input_sequence = x[example_index:example_index + 1, :, :]\n",
        "\n",
        "num_timesteps_to_generate = 1200\n",
        "\n",
        "for _ in range(num_timesteps_to_generate):\n",
        "    predicted_timestep = model.predict(input_sequence[:, -1200:, :])\n",
        "\n",
        "    input_sequence = np.concatenate([input_sequence, predicted_timestep[:, -1:, :]], axis=1)\n",
        "\n",
        "print(\"Generated Sequence Shape:\", input_sequence.shape)"
      ],
      "metadata": {
        "id": "xvc5tHyyKmv_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequence.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_1QvBiTLLH7",
        "outputId": "00640df0-6b66-4580-d872-d22a3e095401"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 2400, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction=input_sequence[:,1200:,:]"
      ],
      "metadata": {
        "id": "WoTLN2WaLzIm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jITfA1XjULSq",
        "outputId": "1e645116-f4c4-4ceb-c571-c6960b2f1c70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1200, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1200):\n",
        "  if prediction[0,i,2]>0.5:\n",
        "    prediction[0,i,2]=1\n",
        "  else:\n",
        "    prediction[0,i,2]=0"
      ],
      "metadata": {
        "id": "zhhUWwayL_I6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(prediction[0,1000:1010])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nETFoZS7MD8k",
        "outputId": "bf88c3c4-97e7-4720-ad46-6b9327ee2aa3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.00441157 -0.00333739  0.        ]\n",
            " [ 0.00441157 -0.0033374   0.        ]\n",
            " [ 0.00441157 -0.00333739  0.        ]\n",
            " [ 0.00441157 -0.00333739  0.        ]\n",
            " [ 0.00441157 -0.0033374   0.        ]\n",
            " [ 0.00441157 -0.00333739  0.        ]\n",
            " [ 0.00441157 -0.0033374   0.        ]\n",
            " [ 0.00441157 -0.0033374   0.        ]\n",
            " [ 0.00441157 -0.00333739  0.        ]\n",
            " [ 0.00441157 -0.00333739  0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install svgwrite"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0xPXHBOlNElv",
        "outputId": "ef5f2f82-9fc5-4fe2-9603-82ee0b9a159d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting svgwrite\n",
            "  Downloading svgwrite-1.4.3-py3-none-any.whl (67 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/67.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/67.1 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.1/67.1 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: svgwrite\n",
            "Successfully installed svgwrite-1.4.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#functions required to get image of generated handwriting from strokes\n",
        "from __future__ import print_function\n",
        "from collections import defaultdict\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from scipy.signal import savgol_filter\n",
        "from scipy.interpolate import interp1d\n",
        "\n",
        "\n",
        "alphabet = [\n",
        "    '\\x00', ' ', '!', '\"', '#', \"'\", '(', ')', ',', '-', '.',\n",
        "    '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';',\n",
        "    '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K',\n",
        "    'L', 'M', 'N', 'O', 'P', 'R', 'S', 'T', 'U', 'V', 'W', 'Y',\n",
        "    'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l',\n",
        "    'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x',\n",
        "    'y', 'z'\n",
        "]\n",
        "alphabet_ord = list(map(ord, alphabet))\n",
        "alpha_to_num = defaultdict(int, list(map(reversed, enumerate(alphabet))))\n",
        "num_to_alpha = dict(enumerate(alphabet_ord))\n",
        "\n",
        "MAX_STROKE_LEN = 1200\n",
        "MAX_CHAR_LEN = 75\n",
        "\n",
        "\n",
        "def align(coords):\n",
        "    \"\"\"\n",
        "    corrects for global slant/offset in handwriting strokes\n",
        "    \"\"\"\n",
        "    coords = np.copy(coords)\n",
        "    X, Y = coords[:, 0].reshape(-1, 1), coords[:, 1].reshape(-1, 1)\n",
        "    X = np.concatenate([np.ones([X.shape[0], 1]), X], axis=1)\n",
        "    offset, slope = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(Y).squeeze()\n",
        "    theta = np.arctan(slope)\n",
        "    rotation_matrix = np.array(\n",
        "        [[np.cos(theta), -np.sin(theta)],\n",
        "         [np.sin(theta), np.cos(theta)]]\n",
        "    )\n",
        "    coords[:, :2] = np.dot(coords[:, :2], rotation_matrix) - offset\n",
        "    return coords\n",
        "\n",
        "\n",
        "def skew(coords, degrees):\n",
        "    \"\"\"\n",
        "    skews strokes by given degrees\n",
        "    \"\"\"\n",
        "    coords = np.copy(coords)\n",
        "    theta = degrees * np.pi/180\n",
        "    A = np.array([[np.cos(-theta), 0], [np.sin(-theta), 1]])\n",
        "    coords[:, :2] = np.dot(coords[:, :2], A)\n",
        "    return coords\n",
        "\n",
        "\n",
        "def stretch(coords, x_factor, y_factor):\n",
        "    \"\"\"\n",
        "    stretches strokes along x and y axis\n",
        "    \"\"\"\n",
        "    coords = np.copy(coords)\n",
        "    coords[:, :2] *= np.array([x_factor, y_factor])\n",
        "    return coords\n",
        "\n",
        "\n",
        "def add_noise(coords, scale):\n",
        "    \"\"\"\n",
        "    adds gaussian noise to strokes\n",
        "    \"\"\"\n",
        "    coords = np.copy(coords)\n",
        "    coords[1:, :2] += np.random.normal(loc=0.0, scale=scale, size=coords[1:, :2].shape)\n",
        "    return coords\n",
        "\n",
        "\n",
        "def encode_ascii(ascii_string):\n",
        "    \"\"\"\n",
        "    encodes ascii string to array of ints\n",
        "    \"\"\"\n",
        "    return np.array(list(map(lambda x: alpha_to_num[x], ascii_string)) + [0])\n",
        "\n",
        "\n",
        "def denoise(coords):\n",
        "    \"\"\"\n",
        "    smoothing filter to mitigate some artifacts of the data collection\n",
        "    \"\"\"\n",
        "    coords = np.split(coords, np.where(coords[:, 2] == 1)[0] + 1, axis=0)\n",
        "    new_coords = []\n",
        "    for stroke in coords:\n",
        "        if len(stroke) != 0:\n",
        "            x_new = savgol_filter(stroke[:, 0], 7, 3, mode='nearest')\n",
        "            y_new = savgol_filter(stroke[:, 1], 7, 3, mode='nearest')\n",
        "            xy_coords = np.hstack([x_new.reshape(-1, 1), y_new.reshape(-1, 1)])\n",
        "            stroke = np.concatenate([xy_coords, stroke[:, 2].reshape(-1, 1)], axis=1)\n",
        "            new_coords.append(stroke)\n",
        "\n",
        "    coords = np.vstack(new_coords)\n",
        "    return coords\n",
        "\n",
        "\n",
        "def interpolate(coords, factor=2):\n",
        "    \"\"\"\n",
        "    interpolates strokes using cubic spline\n",
        "    \"\"\"\n",
        "    coords = np.split(coords, np.where(coords[:, 2] == 1)[0] + 1, axis=0)\n",
        "    new_coords = []\n",
        "    for stroke in coords:\n",
        "\n",
        "        if len(stroke) == 0:\n",
        "            continue\n",
        "\n",
        "        xy_coords = stroke[:, :2]\n",
        "\n",
        "        if len(stroke) > 3:\n",
        "            f_x = interp1d(np.arange(len(stroke)), stroke[:, 0], kind='cubic')\n",
        "            f_y = interp1d(np.arange(len(stroke)), stroke[:, 1], kind='cubic')\n",
        "\n",
        "            xx = np.linspace(0, len(stroke) - 1, factor*(len(stroke)))\n",
        "            yy = np.linspace(0, len(stroke) - 1, factor*(len(stroke)))\n",
        "\n",
        "            x_new = f_x(xx)\n",
        "            y_new = f_y(yy)\n",
        "\n",
        "            xy_coords = np.hstack([x_new.reshape(-1, 1), y_new.reshape(-1, 1)])\n",
        "\n",
        "        stroke_eos = np.zeros([len(xy_coords), 1])\n",
        "        stroke_eos[-1] = 1.0\n",
        "        stroke = np.concatenate([xy_coords, stroke_eos], axis=1)\n",
        "        new_coords.append(stroke)\n",
        "\n",
        "    coords = np.vstack(new_coords)\n",
        "    return coords\n",
        "\n",
        "\n",
        "def normalize(offsets):\n",
        "    \"\"\"\n",
        "    normalizes strokes to median unit norm\n",
        "    \"\"\"\n",
        "    offsets = np.copy(offsets)\n",
        "    offsets[:, :2] /= np.median(np.linalg.norm(offsets[:, :2], axis=1))\n",
        "    return offsets\n",
        "\n",
        "\n",
        "def coords_to_offsets(coords):\n",
        "    \"\"\"\n",
        "    convert from coordinates to offsets\n",
        "    \"\"\"\n",
        "    offsets = np.concatenate([coords[1:, :2] - coords[:-1, :2], coords[1:, 2:3]], axis=1)\n",
        "    offsets = np.concatenate([np.array([[0, 0, 1]]), offsets], axis=0)\n",
        "    return offsets\n",
        "\n",
        "\n",
        "def offsets_to_coords(offsets):\n",
        "    \"\"\"\n",
        "    convert from offsets to coordinates\n",
        "    \"\"\"\n",
        "    return np.concatenate([np.cumsum(offsets[:, :2], axis=0), offsets[:, 2:3]], axis=1)\n",
        "\n",
        "\n",
        "def draw(\n",
        "        offsets,\n",
        "        ascii_seq=None,\n",
        "        align_strokes=True,\n",
        "        denoise_strokes=True,\n",
        "        interpolation_factor=None,\n",
        "        save_file=None\n",
        "):\n",
        "    strokes = offsets_to_coords(offsets)\n",
        "\n",
        "    if denoise_strokes:\n",
        "        strokes = denoise(strokes)\n",
        "\n",
        "    if interpolation_factor is not None:\n",
        "        strokes = interpolate(strokes, factor=interpolation_factor)\n",
        "\n",
        "    if align_strokes:\n",
        "        strokes[:, :2] = align(strokes[:, :2])\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(12, 3))\n",
        "\n",
        "    stroke = []\n",
        "    for x, y, eos in strokes:\n",
        "        stroke.append((x, y))\n",
        "        if eos == 1:\n",
        "            coords = zip(*stroke)\n",
        "            ax.plot(coords[0], coords[1], 'k')\n",
        "            stroke = []\n",
        "    if stroke:\n",
        "        coords = zip(*stroke)\n",
        "        ax.plot(coords[0], coords[1], 'k')\n",
        "        stroke = []\n",
        "\n",
        "    ax.set_xlim(-50, 600)\n",
        "    ax.set_ylim(-40, 40)\n",
        "\n",
        "    ax.set_aspect('equal')\n",
        "    plt.tick_params(\n",
        "        axis='both',\n",
        "        left='off',\n",
        "        top='off',\n",
        "        right='off',\n",
        "        bottom='off',\n",
        "        labelleft='off',\n",
        "        labeltop='off',\n",
        "        labelright='off',\n",
        "        labelbottom='off'\n",
        "    )\n",
        "\n",
        "    if ascii_seq is not None:\n",
        "        if not isinstance(ascii_seq, str):\n",
        "            ascii_seq = ''.join(list(map(chr, ascii_seq)))\n",
        "        plt.title(ascii_seq)\n",
        "\n",
        "    if save_file is not None:\n",
        "        plt.savefig(save_file)\n",
        "        print('saved to {}'.format(save_file))\n",
        "    else:\n",
        "        plt.show()\n",
        "    plt.close('all')"
      ],
      "metadata": {
        "id": "3O6sLazLNcmk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import logging\n",
        "\n",
        "import numpy as np\n",
        "import svgwrite\n",
        "\n",
        "def _draw(strokes,filename, stroke_colors=None, stroke_widths=None):\n",
        "        stroke_colors = stroke_colors or ['black']\n",
        "        stroke_widths = stroke_widths or [2]\n",
        "        line_height = 60\n",
        "        view_width = 1000\n",
        "        view_height = line_height*(len(strokes) + 1)\n",
        "\n",
        "        dwg = svgwrite.Drawing(filename=filename)\n",
        "        dwg.viewbox(width=view_width, height=view_height)\n",
        "        dwg.add(dwg.rect(insert=(0, 0), size=(view_width, view_height), fill='white'))\n",
        "\n",
        "        initial_coord = np.array([0, -(3*line_height / 4)])\n",
        "        for offsets, color, width in zip(strokes,stroke_colors, stroke_widths):\n",
        "\n",
        "            initial_coord[1] -= line_height\n",
        "            offsets[:, :2] *= 1.5\n",
        "            strokes = offsets_to_coords(offsets)\n",
        "            strokes = denoise(strokes)\n",
        "            strokes[:, :2] = align(strokes[:, :2])\n",
        "\n",
        "            strokes[:, 1] *= -1\n",
        "            strokes[:, :2] -= strokes[:, :2].min() + initial_coord\n",
        "            strokes[:, 0] += (view_width - strokes[:, 0].max()) / 2\n",
        "\n",
        "            prev_eos = 1.0\n",
        "            p = \"M{},{} \".format(0, 0)\n",
        "            for x, y, eos in zip(*strokes.T):\n",
        "                p += '{}{},{} '.format('M' if prev_eos == 1.0 else 'L', x, y)\n",
        "                prev_eos = eos\n",
        "            path = svgwrite.path.Path(p)\n",
        "            path = path.stroke(color=color, width=width, linecap='round').fill(\"none\")\n",
        "            dwg.add(path)\n",
        "\n",
        "            initial_coord[1] -= line_height\n",
        "\n",
        "        dwg.save()\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    _draw(prediction,'/content/drive/MyDrive/model/usage_demo.svg')"
      ],
      "metadata": {
        "id": "9yu5aeXZNhtD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}