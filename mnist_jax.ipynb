{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lLJwhPpbFyqm"
      },
      "outputs": [],
      "source": [
        "import jax\n",
        "from sklearn.datasets import fetch_openml\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import jax.numpy as jnp\n",
        "from jax import grad"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mnist = fetch_openml('mnist_784')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U6n_PRwpGM9o",
        "outputId": "cdbeb189-9b9e-4684-9915-36b50fcfeec4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
            "  warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x, y = mnist['data'], mnist['target']\n",
        "x=x/255\n",
        "y=y.astype(jnp.int8)\n",
        "x=jnp.array(x,dtype='int32')\n",
        "y=jnp.array(y,dtype='int32')"
      ],
      "metadata": {
        "id": "F0gzJAm6GW8n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test = x[:60000], x[60000:70000]\n",
        "y_train, y_test = y[:60000], y[60000:70000]\n",
        "\n"
      ],
      "metadata": {
        "id": "DaezeRiIGukQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CTZNvhp9Si3E",
        "outputId": "92834ee9-a2d0-4689-b3c0-cf5d6618782f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 784)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train=x_train.T\n",
        "x_test=x_test.T\n"
      ],
      "metadata": {
        "id": "TKW8N_8vHCib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train=y_train.transpose()\n",
        "y_test=y_test.transpose()"
      ],
      "metadata": {
        "id": "ja4StbTqWR9P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBzrs2U1H8ky",
        "outputId": "1a71e955-4a66-4e26-cb51-d9a105ca9e19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000,)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train=y_train[:, np.newaxis]\n",
        "y_test=y_test[:, np.newaxis]"
      ],
      "metadata": {
        "id": "HdTiA067WWzg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p95B2VpzWbvr",
        "outputId": "90bb4504-f28a-43f9-b11f-70b239c1db19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train=y_train.T\n",
        "y_test=y_test.T"
      ],
      "metadata": {
        "id": "oOxlMfiOX7n_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFFz2exUX7XK",
        "outputId": "988b80a3-c64e-49b8-dace-997b646ef4a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 60000)"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lR4iCjitIHBg",
        "outputId": "6105eae1-1d3a-4295-8d27-97a0d9c4186d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(784, 60000)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if jax.devices(\"gpu\"):\n",
        "    x_train = jax.device_put(x_train, device=jax.devices(\"gpu\")[0])\n",
        "    y_train = jax.device_put(y_train, device=jax.devices(\"gpu\")[0])\n",
        "    x_test = jax.device_put(x_test, device=jax.devices(\"gpu\")[0])\n",
        "    y_test = jax.device_put(y_test, device=jax.devices(\"gpu\")[0])\n",
        "else:\n",
        "    print(\"No GPU available, using CPU.\")"
      ],
      "metadata": {
        "id": "VXExd7l8Lk5p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_train_temp = y_train.reshape(y_train.shape[1],)\n",
        "Y_train = jnp.zeros((Y_train_temp.size, 10))\n",
        "Y_train = Y_train.at[jnp.arange(Y_train_temp.size), Y_train_temp].set(1)\n",
        "Y_train = Y_train.T\n",
        "\n",
        "Y_test_temp = y_test.reshape(y_test.shape[1],)\n",
        "Y_test = jnp.zeros((Y_test_temp.size, 10))\n",
        "Y_test = Y_test.at[jnp.arange(Y_test_temp.size), Y_test_temp].set(1)\n",
        "Y_test = Y_test.T"
      ],
      "metadata": {
        "id": "_Weo3mAH6eyN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_parameters_deep(layer_dims):\n",
        "   key = jax.random.PRNGKey(0)\n",
        "   parameters = {}\n",
        "   L = len(layer_dims)\n",
        "   for l in range(1, L):\n",
        "          weight_key, key = jax.random.split(key)\n",
        "          #parameters['W' + str(l)] =jax.random.normal(key=jax.random.PRNGKey(0), shape=(layer_dims[l], layer_dims[l - 1])) * 0.01\n",
        "          parameters['W' + str(l)] = jax.random.normal(weight_key, shape=(layer_dims[l], layer_dims[l - 1])) * 0.01\n",
        "          parameters['b' + str(l)] =jnp.zeros((layer_dims[l],1))\n",
        "   return parameters"
      ],
      "metadata": {
        "id": "uaB-MO9wJHKn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def linear_forward(A, W, b):\n",
        "    Z=jnp.dot(W,A)+b\n",
        "    cache=(A,W,b)\n",
        "    return Z, cache"
      ],
      "metadata": {
        "id": "O6lH70tyMt1W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(z):\n",
        "   s=1/(1+jnp.exp(-z))\n",
        "   cache=(z)\n",
        "   return s,cache"
      ],
      "metadata": {
        "id": "7iqQ_5y9OxdQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def relu(z):\n",
        "  #s=np.maximum(0,z)\n",
        "  #cache=(z)\n",
        "  return jnp.maximum(0,z),z"
      ],
      "metadata": {
        "id": "9ccRuk22Qj6q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax(z):\n",
        "   s = jnp.exp(z)/jnp.sum(jnp.exp(z), axis = 0, keepdims = True)\n",
        "   #activation_cache = (z)\n",
        "   return s, z"
      ],
      "metadata": {
        "id": "Xqa7HfHhgEHa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def linear_activation_forward(A_prev, W, b, activation):\n",
        "\n",
        "     if activation == \"relu\":\n",
        "        Z, linear_cache = linear_forward(A_prev, W, b)\n",
        "        A, activation_cache=relu(Z)\n",
        "     elif activation == \"softmax\":\n",
        "        Z, linear_cache = linear_forward(A_prev, W, b)\n",
        "        A, activation_cache = softmax(Z)\n",
        "     cache = (linear_cache, activation_cache)\n",
        "\n",
        "     return A, cache"
      ],
      "metadata": {
        "id": "5QGGCrv9OD1d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def L_model_forward(X, parameters):\n",
        "   caches = []\n",
        "   A = X\n",
        "   L = len(parameters) // 2\n",
        "   for l in range(1,L):\n",
        "     A_prev=A\n",
        "     A, cache= linear_activation_forward(A_prev, parameters[\"W\"+str(l)],parameters[\"b\"+str(l)],\"relu\")\n",
        "     caches.append(cache)\n",
        "   AL, cache= linear_activation_forward(A, parameters[\"W\"+str(L)],parameters[\"b\"+str(L)],\"softmax\")\n",
        "\n",
        "   caches.append(cache)\n",
        "\n",
        "   return AL,caches"
      ],
      "metadata": {
        "id": "AAn6eG7Rl_Uy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_cost(AL, Y):\n",
        "    m = Y.shape[1]\n",
        "    cost = - jnp.sum(Y*jnp.log(AL))/m\n",
        "    jnp.squeeze(cost)\n",
        "\n",
        "    return cost"
      ],
      "metadata": {
        "id": "kJpo3NuQhc21"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def linear_backward(dZ, cache):\n",
        "   A_prev, W, b = cache\n",
        "   m = A_prev.shape[1]\n",
        "   dW=(1/m)*(jnp.dot(dZ,A_prev.T))\n",
        "   db=(1/m)*jnp.sum(dZ,axis=1,keepdims=True)\n",
        "   dA_prev=jnp.dot(W.T,dZ)\n",
        "   return dA_prev,dW,db"
      ],
      "metadata": {
        "id": "or87GOAkn4Mn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax_backward(AL, Y):\n",
        "    dZ = AL- Y\n",
        "    return dZ"
      ],
      "metadata": {
        "id": "7Y2G7ttWhzxy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def relu_backward(dA, cache):\n",
        "    Z = cache\n",
        "    dZ = jnp.where(Z > 0, dA, 0)\n",
        "    return dZ"
      ],
      "metadata": {
        "id": "hJ8k1lAXi7tM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def linear_activation_backward(Y,AL,dA, cache, activation):\n",
        "  linear_cache, activation_cache = cache\n",
        "  if activation == \"relu\":\n",
        "    dZ=relu_backward(dA,activation_cache)\n",
        "    dA_prev,dW,db=linear_backward(dZ,linear_cache)\n",
        "  elif activation == \"softmax\":\n",
        "    dZ=softmax_backward(AL,Y)\n",
        "    dA_prev,dW,db=linear_backward(dZ,linear_cache)\n",
        "  return dA_prev, dW, db"
      ],
      "metadata": {
        "id": "kF_2DgOip7Ya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def L_model_backward(AL, Y, caches):\n",
        "  grads = {}\n",
        "  L = len(caches)\n",
        "  m = AL.shape[1]\n",
        "  Y = Y.reshape(AL.shape)\n",
        "  dAL = -Y/AL\n",
        "  #dAL=-(np.divide(Y, AL) - np.divide(1 - Y, 1 - AL))\n",
        "  current_cache = caches[L-1]\n",
        "  dA_prev_temp, dW_temp, db_temp =linear_activation_backward(Y,AL,dAL,current_cache,\"softmax\")\n",
        "  grads[\"dA\" + str(L-1)] = dA_prev_temp\n",
        "  grads[\"dW\" + str(L)] = dW_temp\n",
        "  grads[\"db\" + str(L)] = db_temp\n",
        "  for l in reversed(range(L-1)):\n",
        "    current_cache = caches[l]\n",
        "    dA_prev_temp, dW_temp, db_temp =linear_activation_backward(Y,AL,grads[\"dA\"+str(l+1)],current_cache,\"relu\")\n",
        "    grads[\"dA\" + str(l)] = dA_prev_temp\n",
        "    grads[\"dW\" + str(l+1)] = dW_temp\n",
        "    grads[\"db\" + str(l+1)] = db_temp\n",
        "  return grads"
      ],
      "metadata": {
        "id": "Stunl980wV4m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def update_parameters(params, grads, learning_rate):\n",
        "  parameters = params.copy()\n",
        "  L = len(parameters) // 2\n",
        "  for l in range(L):\n",
        "        parameters[\"W\" + str(l+1)] =parameters[\"W\" + str(l+1)]-learning_rate*grads[\"dW\"+str(l+1)]\n",
        "        parameters[\"b\" + str(l+1)] =parameters[\"b\" + str(l+1)]-learning_rate*grads[\"db\"+str(l+1)]\n",
        "\n",
        "        # YOUR CODE ENDS HERE\n",
        "  return parameters"
      ],
      "metadata": {
        "id": "6VC3M-3Pzvvy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_predictions(Y_hat):\n",
        "    return jnp.argmax(Y_hat,0)\n",
        "\n",
        "def get_accuracy(predictions,Y):\n",
        "    predictions = predictions.reshape(1,predictions.shape[0])\n",
        "    #print(predictions.shape)\n",
        "    ans = 0\n",
        "    for i in range(Y.shape[1]) :\n",
        "        predict = predictions[0,i]\n",
        "        if Y[predict,i]==1 :\n",
        "            ans+=1\n",
        "   # print(ans)\n",
        "    return str((ans/Y.shape[1])*100) + '%'"
      ],
      "metadata": {
        "id": "PCIpj1ltlpwu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "layers_dims = [784, 30, 20, 10]"
      ],
      "metadata": {
        "id": "249Bf9qQ3oGx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def L_layer_model(X, Y, layers_dims, learning_rate = 0.0075, num_iterations = 3000,print_cost=False):\n",
        "  #np.random.seed(1)\n",
        "  grads = {}\n",
        "  costs = []\n",
        "  m = X.shape[1]\n",
        "  #print(layers_dims)\n",
        "  cost = 2.5\n",
        "  parameters=initialize_parameters_deep(layers_dims)\n",
        "  for i in range(0, num_iterations):\n",
        "    AL, caches=L_model_forward(X, parameters)\n",
        "    grads=L_model_backward(AL, Y, caches)\n",
        "    parameters=update_parameters(parameters, grads, learning_rate)\n",
        "    cost = compute_cost(AL,Y)\n",
        "#    Y_predict = jnp.zeros(AL.shape)\n",
        "    Y_predict = jnp.zeros_like(AL)\n",
        "    indices = (jnp.argmax(AL, axis=0), jnp.arange(AL.shape[1]))\n",
        "    Y_predict = Y_predict.at[indices].set(1)\n",
        "   # Y_predict = jax.ops.index_update(Y_predict, indices, 1)\n",
        "   # Y_predict[jnp.argmax(AL, axis = 0), jnp.arange(AL.shape[1])] = 1\n",
        "   # if i%100:\n",
        "    #  learning_rate=learning_rate/(1+0.0002)\n",
        "    if print_cost and i % 100 == 0 or i == num_iterations - 1:\n",
        "            print(\"Cost after iteration {}: {}\".format(i, jnp.squeeze(cost)))\n",
        "            print(learning_rate)\n",
        "            #print(\"train accuracy: {} %\".format(100 - np.mean(np.abs(Y_predict - Y)) * 100))\n",
        "          #  print(\"accuracy : \" , get_accuracy(get_predictions(AL),Y))\n",
        "\n",
        "    if i % 100 == 0 or i == num_iterations:\n",
        "            costs.append(cost)\n",
        "\n",
        "  return parameters,costs, Y_predict,AL"
      ],
      "metadata": {
        "id": "zUxqJAdp0MDF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parameters, costs, Y_predict,AL =L_layer_model(x_train,Y_train, layers_dims, 0.8, 3000, True)\n",
        "print(\"accuracy : \" , get_accuracy(get_predictions(AL),Y_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gavmHWii2j40",
        "outputId": "62e589ff-96a9-4386-f534-93c1396039b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cost after iteration 0: 2.302584409713745\n",
            "0.8\n",
            "Cost after iteration 100: 2.3011558055877686\n",
            "0.8\n",
            "Cost after iteration 200: 2.3011536598205566\n",
            "0.8\n",
            "Cost after iteration 300: 2.3011510372161865\n",
            "0.8\n",
            "Cost after iteration 400: 2.3011474609375\n",
            "0.8\n",
            "Cost after iteration 500: 2.3011417388916016\n",
            "0.8\n",
            "Cost after iteration 600: 2.3011317253112793\n",
            "0.8\n",
            "Cost after iteration 700: 2.3011131286621094\n",
            "0.8\n",
            "Cost after iteration 800: 2.301072120666504\n",
            "0.8\n",
            "Cost after iteration 900: 2.30096173286438\n",
            "0.8\n",
            "Cost after iteration 1000: 2.300509452819824\n",
            "0.8\n",
            "Cost after iteration 1100: 2.2958993911743164\n",
            "0.8\n",
            "Cost after iteration 1200: 2.221557140350342\n",
            "0.8\n",
            "Cost after iteration 1300: 2.1743087768554688\n",
            "0.8\n",
            "Cost after iteration 1400: 2.086869478225708\n",
            "0.8\n",
            "Cost after iteration 1500: 2.064865827560425\n",
            "0.8\n",
            "Cost after iteration 1600: 1.9783920049667358\n",
            "0.8\n",
            "Cost after iteration 1700: 1.9253406524658203\n",
            "0.8\n",
            "Cost after iteration 1800: 1.8988292217254639\n",
            "0.8\n",
            "Cost after iteration 1900: 1.860556960105896\n",
            "0.8\n",
            "Cost after iteration 2000: 1.8300095796585083\n",
            "0.8\n",
            "Cost after iteration 2100: 1.7580821514129639\n",
            "0.8\n",
            "Cost after iteration 2200: 1.7380211353302002\n",
            "0.8\n",
            "Cost after iteration 2300: 1.749074101448059\n",
            "0.8\n",
            "Cost after iteration 2400: 1.7169959545135498\n",
            "0.8\n",
            "Cost after iteration 2500: 1.6850533485412598\n",
            "0.8\n",
            "Cost after iteration 2600: 1.7241525650024414\n",
            "0.8\n",
            "Cost after iteration 2700: 1.6793279647827148\n",
            "0.8\n",
            "Cost after iteration 2800: 1.658515214920044\n",
            "0.8\n",
            "Cost after iteration 2900: 1.669110655784607\n",
            "0.8\n",
            "Cost after iteration 2999: 1.6707864999771118\n",
            "0.8\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-85-3a10b4617153>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcosts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_predict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mAL\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mL_layer_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"accuracy : \"\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mget_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-33-0bc533298ab3>\u001b[0m in \u001b[0;36mget_accuracy\u001b[0;34m(predictions, Y)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m             \u001b[0mans\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m    \u001b[0;31m# print(ans)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/numpy/array_methods.py\u001b[0m in \u001b[0;36mdeferring_binary_op\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mswap\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_accepted_binop_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mbinary_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_rejected_binop_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m       raise TypeError(f\"unsupported operand type(s) for {opchar}: \"\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mz_VLNfWQjSc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}