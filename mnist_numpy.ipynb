{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lLJwhPpbFyqm"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mnist = fetch_openml('mnist_784')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U6n_PRwpGM9o",
        "outputId": "7c50e88c-e5ab-43a8-9e41-7576187b3a80"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
            "  warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x, y = mnist['data'], mnist['target']\n",
        "x=x/255\n",
        "y=y.astype(np.int8)"
      ],
      "metadata": {
        "id": "F0gzJAm6GW8n"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test = x[:60000], x[60000:70000]\n",
        "y_train, y_test = y[:60000], y[60000:70000]\n",
        "\n"
      ],
      "metadata": {
        "id": "DaezeRiIGukQ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train=x_train.values.reshape(784,60000)\n",
        "x_test=x_test.values.reshape(784,10000)\n",
        "y_train=y_train.values.reshape(1,60000)\n",
        "y_test=y_test.values.reshape(1,10000)"
      ],
      "metadata": {
        "id": "TKW8N_8vHCib"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBzrs2U1H8ky",
        "outputId": "997f9de2-234f-48fc-f21e-aa1816b0eada"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 10000)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lR4iCjitIHBg",
        "outputId": "fa9955ff-ad3c-4ae8-ce69-41a640b82419"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(784, 60000)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_train_temp = y_train.reshape(y_train.shape[1],)\n",
        "Y_train = np.zeros((Y_train_temp.size,10))\n",
        "Y_train[np.arange(Y_train_temp.size),Y_train_temp] = 1\n",
        "Y_train = Y_train.T\n",
        "Y_test_temp = y_test.reshape(y_test.shape[1],)\n",
        "Y_test = np.zeros((Y_test_temp.size,10))\n",
        "Y_test[np.arange(Y_test_temp.size),Y_test_temp] = 1\n",
        "Y_test = Y_test.T"
      ],
      "metadata": {
        "id": "yw4bcH6wzWvj"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_parameters_deep(layer_dims):\n",
        "   parameters = {}\n",
        "   L = len(layer_dims)\n",
        "   for l in range(1, L):\n",
        "          parameters['W' + str(l)] =np.random.randn(layer_dims[l],layer_dims[l-1])*0.01\n",
        "          parameters['b' + str(l)] =np.zeros((layer_dims[l],1))\n",
        "   return parameters"
      ],
      "metadata": {
        "id": "uaB-MO9wJHKn"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def linear_forward(A, W, b):\n",
        "    Z=np.dot(W,A)+b\n",
        "    cache=(A,W,b)\n",
        "    return Z, cache"
      ],
      "metadata": {
        "id": "O6lH70tyMt1W"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(z):\n",
        "   s=1/(1+np.exp(-z))\n",
        "   cache=(z)\n",
        "   return s,cache"
      ],
      "metadata": {
        "id": "7iqQ_5y9OxdQ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def relu(z):\n",
        "  #s=np.maximum(0,z)\n",
        "  #cache=(z)\n",
        "  return np.maximum(0,z),z"
      ],
      "metadata": {
        "id": "9ccRuk22Qj6q"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax(z):\n",
        "   s = np.exp(z)/np.sum(np.exp(z), axis = 0, keepdims = True)\n",
        "   #activation_cache = (z)\n",
        "   return s, z"
      ],
      "metadata": {
        "id": "Xqa7HfHhgEHa"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def linear_activation_forward(A_prev, W, b, activation):\n",
        "\n",
        "     if activation == \"relu\":\n",
        "        Z, linear_cache = linear_forward(A_prev, W, b)\n",
        "        A, activation_cache=relu(Z)\n",
        "     elif activation == \"softmax\":\n",
        "        Z, linear_cache = linear_forward(A_prev, W, b)\n",
        "        A, activation_cache = softmax(Z)\n",
        "     cache = (linear_cache, activation_cache)\n",
        "\n",
        "     return A, cache"
      ],
      "metadata": {
        "id": "5QGGCrv9OD1d"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def L_model_forward(X, parameters):\n",
        "   caches = []\n",
        "   A = X\n",
        "   L = len(parameters) // 2\n",
        "   for l in range(1,L):\n",
        "     A_prev=A\n",
        "     A, cache= linear_activation_forward(A_prev, parameters[\"W\"+str(l)],parameters[\"b\"+str(l)],\"relu\")\n",
        "     caches.append(cache)\n",
        "   AL, cache= linear_activation_forward(A, parameters[\"W\"+str(L)],parameters[\"b\"+str(L)],\"softmax\")\n",
        "\n",
        "   caches.append(cache)\n",
        "\n",
        "   return AL,caches"
      ],
      "metadata": {
        "id": "AAn6eG7Rl_Uy"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_cost(AL, Y):\n",
        "    m = Y.shape[1]\n",
        "    cost = - np.sum(Y*np.log(AL))/m\n",
        "    np.squeeze(cost)\n",
        "\n",
        "    return cost"
      ],
      "metadata": {
        "id": "kJpo3NuQhc21"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def linear_backward(dZ, cache):\n",
        "   A_prev, W, b = cache\n",
        "   m = A_prev.shape[1]\n",
        "   dW=(1/m)*(np.dot(dZ,A_prev.T))\n",
        "   db=(1/m)*np.sum(dZ,axis=1,keepdims=True)\n",
        "   dA_prev=np.dot(W.T,dZ)\n",
        "   return dA_prev,dW,db"
      ],
      "metadata": {
        "id": "or87GOAkn4Mn"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax_backward(AL, Y):\n",
        "    dZ = AL- Y\n",
        "    return dZ"
      ],
      "metadata": {
        "id": "7Y2G7ttWhzxy"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def relu_backward(dA, cache):\n",
        "    Z = cache\n",
        "    dZ = np.where(Z > 0, dA, 0)\n",
        "    return dZ"
      ],
      "metadata": {
        "id": "hJ8k1lAXi7tM"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def linear_activation_backward(Y,AL,dA, cache, activation):\n",
        "  linear_cache, activation_cache = cache\n",
        "  if activation == \"relu\":\n",
        "    dZ=relu_backward(dA,activation_cache)\n",
        "    dA_prev,dW,db=linear_backward(dZ,linear_cache)\n",
        "  elif activation == \"softmax\":\n",
        "    dZ=softmax_backward(AL,Y)\n",
        "    dA_prev,dW,db=linear_backward(dZ,linear_cache)\n",
        "  return dA_prev, dW, db"
      ],
      "metadata": {
        "id": "kF_2DgOip7Ya"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def L_model_backward(AL, Y, caches):\n",
        "  grads = {}\n",
        "  L = len(caches)\n",
        "  m = AL.shape[1]\n",
        "  Y = Y.reshape(AL.shape)\n",
        "  dAL = -Y/AL\n",
        "  #dAL=-(np.divide(Y, AL) - np.divide(1 - Y, 1 - AL))\n",
        "  current_cache = caches[L-1]\n",
        "  dA_prev_temp, dW_temp, db_temp =linear_activation_backward(Y,AL,dAL,current_cache,\"softmax\")\n",
        "  grads[\"dA\" + str(L-1)] = dA_prev_temp\n",
        "  grads[\"dW\" + str(L)] = dW_temp\n",
        "  grads[\"db\" + str(L)] = db_temp\n",
        "  for l in reversed(range(L-1)):\n",
        "    current_cache = caches[l]\n",
        "    dA_prev_temp, dW_temp, db_temp =linear_activation_backward(Y,AL,grads[\"dA\"+str(l+1)],current_cache,\"relu\")\n",
        "    grads[\"dA\" + str(l)] = dA_prev_temp\n",
        "    grads[\"dW\" + str(l+1)] = dW_temp\n",
        "    grads[\"db\" + str(l+1)] = db_temp\n",
        "  return grads"
      ],
      "metadata": {
        "id": "Stunl980wV4m"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def update_parameters(params, grads, learning_rate):\n",
        "  parameters = params.copy()\n",
        "  L = len(parameters) // 2\n",
        "  for l in range(L):\n",
        "        parameters[\"W\" + str(l+1)] =parameters[\"W\" + str(l+1)]-learning_rate*grads[\"dW\"+str(l+1)]\n",
        "        parameters[\"b\" + str(l+1)] =parameters[\"b\" + str(l+1)]-learning_rate*grads[\"db\"+str(l+1)]\n",
        "\n",
        "        # YOUR CODE ENDS HERE\n",
        "  return parameters"
      ],
      "metadata": {
        "id": "6VC3M-3Pzvvy"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_predictions(Y_hat):\n",
        "    return np.argmax(Y_hat,0)\n",
        "\n",
        "def get_accuracy(predictions,Y):\n",
        "    predictions = predictions.reshape(1,predictions.shape[0])\n",
        "    #print(predictions.shape)\n",
        "    ans = 0\n",
        "    for i in range(Y.shape[1]) :\n",
        "        predict = predictions[0,i]\n",
        "        if Y[predict,i]==1 :\n",
        "            ans+=1\n",
        "   # print(ans)\n",
        "    return str((ans/Y.shape[1])*100) + '%'"
      ],
      "metadata": {
        "id": "PCIpj1ltlpwu"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "layers_dims = [784, 30, 20, 10]"
      ],
      "metadata": {
        "id": "249Bf9qQ3oGx"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def L_layer_model(X, Y, layers_dims, learning_rate = 0.0075, num_iterations = 3000,print_cost=False):\n",
        "  #np.random.seed(1)\n",
        "  grads = {}\n",
        "  costs = []\n",
        "  m = X.shape[1]\n",
        "  #print(layers_dims)\n",
        "  cost = 2.5\n",
        "  parameters=initialize_parameters_deep(layers_dims)\n",
        "  for i in range(0, num_iterations):\n",
        "    AL, caches=L_model_forward(X, parameters)\n",
        "    grads=L_model_backward(AL, Y, caches)\n",
        "    parameters=update_parameters(parameters, grads, learning_rate)\n",
        "    cost = compute_cost(AL,Y)\n",
        "    Y_predict = np.zeros(AL.shape)\n",
        "    Y_predict[np.argmax(AL, axis = 0), np.arange(AL.shape[1])] = 1\n",
        "    if print_cost and i % 100 == 0 or i == num_iterations - 1:\n",
        "            print(\"Cost after iteration {}: {}\".format(i, np.squeeze(cost)))\n",
        "            #print(\"train accuracy: {} %\".format(100 - np.mean(np.abs(Y_predict - Y)) * 100))\n",
        "            print(\"accuracy : \" , get_accuracy(get_predictions(AL),Y))\n",
        "\n",
        "    if i % 100 == 0 or i == num_iterations:\n",
        "            costs.append(cost)\n",
        "\n",
        "  return parameters,costs, Y_predict"
      ],
      "metadata": {
        "id": "zUxqJAdp0MDF"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parameters, costs, Y_predict =L_layer_model(x_train,Y_train, layers_dims, 0.2, 2500, True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gavmHWii2j40",
        "outputId": "f850d3c8-1689-479d-a0c1-78856ef23488"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cost after iteration 0: 2.30258520512949\n",
            "accuracy :  9.411666666666667%\n",
            "Cost after iteration 100: 2.301182379512185\n",
            "accuracy :  11.236666666666666%\n",
            "Cost after iteration 200: 2.301159171326631\n",
            "accuracy :  11.236666666666666%\n",
            "Cost after iteration 300: 2.301158597961851\n",
            "accuracy :  11.236666666666666%\n",
            "Cost after iteration 400: 2.301158439874312\n",
            "accuracy :  11.236666666666666%\n",
            "Cost after iteration 500: 2.3011582726101962\n",
            "accuracy :  11.236666666666666%\n",
            "Cost after iteration 600: 2.3011580982959186\n",
            "accuracy :  11.236666666666666%\n",
            "Cost after iteration 700: 2.301157936278211\n",
            "accuracy :  11.236666666666666%\n",
            "Cost after iteration 800: 2.3011577973837585\n",
            "accuracy :  11.236666666666666%\n",
            "Cost after iteration 900: 2.3011576628548336\n",
            "accuracy :  11.236666666666666%\n",
            "Cost after iteration 1000: 2.301157533160655\n",
            "accuracy :  11.236666666666666%\n",
            "Cost after iteration 1100: 2.3011574106133383\n",
            "accuracy :  11.236666666666666%\n",
            "Cost after iteration 1200: 2.3011573005518406\n",
            "accuracy :  11.236666666666666%\n",
            "Cost after iteration 1300: 2.3011571932421875\n",
            "accuracy :  11.236666666666666%\n",
            "Cost after iteration 1400: 2.3011570814487814\n",
            "accuracy :  11.236666666666666%\n",
            "Cost after iteration 1500: 2.301156971864244\n",
            "accuracy :  11.236666666666666%\n",
            "Cost after iteration 1600: 2.3011568635882784\n",
            "accuracy :  11.236666666666666%\n",
            "Cost after iteration 1700: 2.30115675176097\n",
            "accuracy :  11.236666666666666%\n",
            "Cost after iteration 1800: 2.3011566360494133\n",
            "accuracy :  11.236666666666666%\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-de6cf5a8e373>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcosts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_predict\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mL_layer_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-25-fc5a08cabc46>\u001b[0m in \u001b[0;36mL_layer_model\u001b[0;34m(X, Y, layers_dims, learning_rate, num_iterations, print_cost)\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mAL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaches\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mL_model_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mgrads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mL_model_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mparameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupdate_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_cost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAL\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-9d0f67dfcd1f>\u001b[0m in \u001b[0;36mL_model_backward\u001b[0;34m(AL, Y, caches)\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0;31m#dAL=-(np.divide(Y, AL) - np.divide(1 - Y, 1 - AL))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mcurrent_cache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcaches\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m   \u001b[0mdA_prev_temp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdW_temp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdb_temp\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mlinear_activation_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mAL\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdAL\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcurrent_cache\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"softmax\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m   \u001b[0mgrads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"dA\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdA_prev_temp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0mgrads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"dW\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdW_temp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-e21cae80a855>\u001b[0m in \u001b[0;36mlinear_activation_backward\u001b[0;34m(Y, AL, dA, cache, activation)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mlinear_activation_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mAL\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0mlinear_cache\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation_cache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"relu\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdZ\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrelu_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactivation_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mdA_prev\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdW\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlinear_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdZ\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlinear_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}